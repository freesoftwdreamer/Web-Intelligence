import torch
from transformers import BertTokenizer, BertForSequenceClassification
from bs4 import BeautifulSoup
import requests
import pandas as pd

# Load the fine-tuned model and tokenizer from the local directory
model_name = './fine_tuned_model'
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForSequenceClassification.from_pretrained(model_name)

# Move the model to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Keywords to classify as non-e-commerce
non_ecommerce_keywords = ["Barbershop", "Notarfachangestellte", "Friseursalon", "Rechtsanwälte", "Zahnarzt", "schnitt", "Sauna","Therme","elektrotechnik","Sanitär","Modelle"]

# E-commerce keywords
ecommerce_keywords = [
    'Kundenerkennung',
    'Individuelle Preisgestaltung',
    'Sitzungsmanagement',
    'cart',
    'online',
    'shop',
    'Online-Shop',
    'leistungen',
    'Leinstungen',
    'service',
    'Service',
    'Reservierung',
    'versicherung',
    'Mitgliedschaft',
    'datenshutz',
    'BUCHEN',
    'Book',
    'BOOK',
    'Booking',
    'booking',
    'rentcar',
    'rentacar',
    'rent',
    'Rental',
    'reservation',
    'checkout',
    'payment',
    'pay',
    'Transporter Mieten',
    'Buchung',
    'buchung',
    'buchen',
    'DIRECTBUCHUNG',
    'Kostenlose Rücksendung',
    'been blocked by bot',
    'robots',
    'Vorteilswelt',
    'Zimmer',
    'ZIMMER',
    'Einkaufswagen',
    'Ticket'
]

# Function to extract text from HTML
def extract_text(html):
    soup = BeautifulSoup(html, 'html.parser')
    return soup.get_text()

# Function to classify a URL as e-commerce or not
def classify_url(url):
    try:
        response = requests.get(url)
        response.raise_for_status()  # Raise an error for bad responses
        text = extract_text(response.text)

        # Check for non-e-commerce keywords
        if any(keyword in text for keyword in non_ecommerce_keywords):
            return 0

        # Check for e-commerce keywords
        if any(keyword in text for keyword in ecommerce_keywords):
            return 1

        # Use the BERT model for classification
        inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding=True)
        inputs = {key: value.to(device) for key, value in inputs.items()}
        outputs = model(**inputs)
        logits = outputs.logits
        probabilities = torch.softmax(logits, dim=-1)
        prediction = torch.argmax(probabilities, dim=-1).item()
        return prediction

    except (requests.exceptions.RequestException, ValueError) as e:
        print(f"Error processing URL {url}: {e}")
        return None

# Function to process a CSV file with URLs and save the results
def process_csv(csv_file, url_column, output_file):
    df = pd.read_csv(csv_file)
    results = []
    for index, row in df.iterrows():
        url = row[url_column]  # Use the specified URL column
        is_ecommerce = classify_url(url)
        if is_ecommerce is not None:
            results.append({'URL': url, 'Is E-commerce': is_ecommerce})

    # Convert results to DataFrame and save to CSV
    results_df = pd.DataFrame(results)
    results_df.to_csv(output_file, index=False)
    print(f"Results saved to {output_file}")

# Example usage
csv_file = 'NEWDEinput.csv'
url_column = 'url'  # Specify the column name for URLs
output_file = 'classified_urls_DE.csv'  # Specify the output file name
process_csv(csv_file, url_column, output_file)
